{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "Lexical Simplification with BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArmandDS/lexical_simplification_bert/blob/master/Lexical_Simplification_with_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOCImRwg5Om-",
        "colab_type": "text"
      },
      "source": [
        "## Load the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MRqUkLYoa0h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "7ba06074-45d1-4e05-b4f2-dcbcdb12ddea"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple\n",
        "from nltk import word_tokenize\n",
        "from functools import lru_cache\n",
        "import re\n",
        "import unicodedata\n",
        "import sys\n",
        "from collections import Counter\n",
        "import nltk\n",
        "nltk.download('brown')\n",
        "from nltk.corpus import brown\n",
        "from nltk import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import pos_tag\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57AUXjgM4rn5",
        "colab_type": "text"
      },
      "source": [
        "## First part: The Complex Word Identification Model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ag-5krPia3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "Dataset = namedtuple('Dataset', 'name, train, test')\n",
        "Model = namedtuple('Model', 'type, name, dimension, corpus, model')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPPVep68474C",
        "colab_type": "text"
      },
      "source": [
        "Get the dataset to train the CWI model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ga12AgFHiyN2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d3c71681-c694-4e49-9ce4-95718e9cc734"
      },
      "source": [
        "!wget https://www.inf.uni-hamburg.de/en/inst/ab/lt/resources/data/complex-word-identification-dataset/cwishareddataset.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-27 16:23:17--  https://www.inf.uni-hamburg.de/en/inst/ab/lt/resources/data/complex-word-identification-dataset/cwishareddataset.zip\n",
            "Resolving www.inf.uni-hamburg.de (www.inf.uni-hamburg.de)... 134.100.36.5\n",
            "Connecting to www.inf.uni-hamburg.de (www.inf.uni-hamburg.de)|134.100.36.5|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1075894 (1.0M) [application/zip]\n",
            "Saving to: ‘cwishareddataset.zip’\n",
            "\n",
            "cwishareddataset.zi 100%[===================>]   1.03M  3.38MB/s    in 0.3s    \n",
            "\n",
            "2020-08-27 16:23:18 (3.38 MB/s) - ‘cwishareddataset.zip’ saved [1075894/1075894]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upShTZSAjMVW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "ae8fdc20-dca0-483d-d3d1-50c554a980d9"
      },
      "source": [
        "!unzip cwishareddataset.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  cwishareddataset.zip\n",
            "   creating: traindevset/\n",
            "   creating: traindevset/german/\n",
            "  inflating: traindevset/german/German_Train.tsv  \n",
            "  inflating: traindevset/german/German_Dev.tsv  \n",
            "  inflating: traindevset/README.md   \n",
            "   creating: traindevset/english/\n",
            "  inflating: traindevset/english/WikiNews_Train.tsv  \n",
            "  inflating: traindevset/english/Wikipedia_Train.tsv  \n",
            "  inflating: traindevset/english/Wikipedia_Dev.tsv  \n",
            "  inflating: traindevset/english/News_Dev.tsv  \n",
            "  inflating: traindevset/english/News_Train.tsv  \n",
            "  inflating: traindevset/english/WikiNews_Dev.tsv  \n",
            "   creating: traindevset/spanish/\n",
            "  inflating: traindevset/spanish/Spanish_Train.tsv  \n",
            "  inflating: traindevset/spanish/Spanish_Dev.tsv  \n",
            "  inflating: README.md               \n",
            "   creating: testset/\n",
            "   creating: testset/german/\n",
            "  inflating: testset/german/German_Test.tsv  \n",
            "  inflating: testset/README.md       \n",
            "   creating: testset/english/\n",
            "  inflating: testset/english/Wikipedia_Test.tsv  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/testset/\n",
            "   creating: __MACOSX/testset/english/\n",
            "  inflating: __MACOSX/testset/english/._Wikipedia_Test.tsv  \n",
            "  inflating: testset/english/WikiNews_Test.tsv  \n",
            "  inflating: testset/english/News_Test.tsv  \n",
            "   creating: testset/french/\n",
            "  inflating: testset/french/French_Test.tsv  \n",
            "   creating: testset/spanish/\n",
            "  inflating: testset/spanish/Spanish_Test.tsv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgMuNkitia3a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "MAIN_PATH_DATASET = \"traindevset/english/\"\n",
        "genres = ['Wikipedia', 'WikiNews', 'News']\n",
        "datasets = ['Train', 'Dev']\n",
        "columns = ['id', 'sentence', \"start\", \"end\", \"target\", \n",
        "           \"nat\", \"non_nat\", \"nat_marked\", \"non_nat_marked\", \"binary\", \"prob\"]\n",
        "\n",
        "\n",
        "datasets = [Dataset('Wikipedia', 'Train', 'Dev'),\n",
        "            Dataset('WikiNews', 'Train', 'Dev'),\n",
        "            Dataset('News', 'Train', 'Dev')]\n",
        "\n",
        "feature_categories = []\n",
        "\n",
        "def load_df(path):\n",
        "    df = pd.read_csv(path, header=None, sep = \"\\t\")\n",
        "    df.columns = columns\n",
        "    return df\n",
        "\n",
        "datasets = [Dataset(d.name, load_df(MAIN_PATH_DATASET + d.name + '_' + d.train + '.tsv'),\n",
        "                            load_df(MAIN_PATH_DATASET + d.name + '_' + d.test + '.tsv'))\n",
        "                            for d in datasets]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5ejPkqT5jmj",
        "colab_type": "text"
      },
      "source": [
        "Get the glove embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qYxKCLK5gah",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "e8878662-6000-497c-ce2a-11a1d654872c"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-27 16:23:18--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-08-27 16:23:19--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-08-27 16:23:19--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.20MB/s    in 6m 30s  \n",
            "\n",
            "2020-08-27 16:29:49 (2.11 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfUpcaeP9Y_k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "9d2f0fc1-cfaf-4000-b1f9-43c3728368e6"
      },
      "source": [
        "!unzip glove.6B.zip -d embeddings"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: embeddings/glove.6B.50d.txt  \n",
            "  inflating: embeddings/glove.6B.100d.txt  \n",
            "  inflating: embeddings/glove.6B.200d.txt  \n",
            "  inflating: embeddings/glove.6B.300d.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqCBKkUQ5uo3",
        "colab_type": "text"
      },
      "source": [
        "Load the embedding model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqljIkbiia3n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "a1e5d2f3-d7a7-474d-8eb2-56f2ac95034f"
      },
      "source": [
        "from gensim.test.utils import datapath, get_tmpfile\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "\n",
        "MAIN_PATH = 'embeddings/'\n",
        "\n",
        "\n",
        "glove_models = []\n",
        "\n",
        "glove_defs = [ Model('glove', 'glove.6B.300d.txt', 300, 'wikipedia+gigaword5', None)]\n",
        "              \n",
        "for model in glove_defs:\n",
        "    glove_file = MAIN_PATH + model.name\n",
        "    tmp_file = get_tmpfile(model.name + '-temp')\n",
        "    glove2word2vec(glove_file, tmp_file)\n",
        "    vecs = KeyedVectors.load_word2vec_format(tmp_file)\n",
        "    glove_models.append(Model(model.type, model.name, model.dimension, model.corpus, vecs))\n",
        "    print('load model : {}'.format(model.name))\n",
        "    \n",
        "print(glove_models)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "load model : glove.6B.300d.txt\n",
            "[Model(type='glove', name='glove.6B.300d.txt', dimension=300, corpus='wikipedia+gigaword5', model=<gensim.models.keyedvectors.Word2VecKeyedVectors object at 0x7f0e95e40be0>)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GRQVuEl6h6j",
        "colab_type": "text"
      },
      "source": [
        "Process the Dataset in order to formated it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvG6w6C0ia33",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataframe = datasets[0].train[0:30]\n",
        "\n",
        "def overlaps(start1, end1, start2, end2):\n",
        "    return bool(range(max(start1, start2), min(end1, end2)+1))\n",
        "\n",
        "def extract_ngrams_group(group):\n",
        "    targets = zip(group['target'].values.tolist(), group['start'].values.tolist(),\n",
        "                 group['end'].values.tolist(), group['binary'].values.tolist())\n",
        "    for word, start, end, binary in targets:\n",
        "        tokens = word.split()\n",
        "        if len(tokens)>1:\n",
        "            olap_words = [(w, b) for w, s, e, b in targets if overlaps(start, end, s, e)]\n",
        "            \n",
        "    \n",
        "grouped = dataframe.groupby('sentence').apply(lambda group : extract_ngrams_group(group))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uu71-KwsFKbL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aceca825-56c5-44bb-f2eb-60f25a89d239"
      },
      "source": [
        "wordlist_lowercased = set(i.lower() for i in brown.words())\n",
        "print (len(wordlist_lowercased))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49815\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1axsJ5Jia4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tbl = dict.fromkeys(i for i in range(sys.maxunicode)\n",
        "                      if unicodedata.category(chr(i)).startswith('P'))\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    return text.translate(tbl)\n",
        "\n",
        "@lru_cache(maxsize=None)\n",
        "def all_tokens_with_index(context):\n",
        "    curr_pos = 0\n",
        "    targets = []\n",
        "    j = 0\n",
        "    w = 0\n",
        "    curr_split = ''\n",
        "    ctx_split = context.split()\n",
        "    whitespaces = re.findall('\\s+', context)\n",
        "    num_whitespaces = [len(token) for token in whitespaces]\n",
        "    num_whitespaces.append(1)\n",
        "    tokens = word_tokenize(context)\n",
        "    tokens = ['\"' if token not in context else token for token in tokens]\n",
        "    for index, token in enumerate(tokens, 1):\n",
        "        targets.append((token, index, curr_pos, (curr_pos + len(token))))\n",
        "        curr_pos += len(token)\n",
        "        curr_split += token\n",
        "        if ctx_split[j] == curr_split:\n",
        "            curr_pos += num_whitespaces[w]\n",
        "            j += 1\n",
        "            w += 1\n",
        "            curr_split = ''\n",
        "    return [val for val in targets if val[0] != '\"']\n",
        "\n",
        "def build_vocabulary(sentences, embedding_model, dimension):\n",
        "    all_words = [tpl[0] for sentence in sentences for tpl in sentence['seq']] + list(wordlist_lowercased)\n",
        "    print('# Words : {}'.format(len(all_words)))\n",
        "    counter = Counter(all_words)\n",
        "    vocab_size = len(counter) + 1\n",
        "    print('# Vocab : {}'.format(vocab_size))\n",
        "    print('# embeding model  : {}'.format(len(embedding_model.vocab)))   \n",
        "    word2index = {word : index for index, (word, count) in enumerate(counter.most_common(), 1)}\n",
        "    index2word = {index : word for word, index in word2index.items()}\n",
        "    # +1 required for pad token\n",
        "    embedding_matrix = np.zeros(((vocab_size), dimension))\n",
        "    missing_embed_words = []\n",
        "    i_ = 0\n",
        "    for word, index in word2index.items():\n",
        "        if word in embedding_model.vocab:\n",
        "            embedding = embedding_model[word]\n",
        "        else:\n",
        "             i_ +=1\n",
        "             continue\n",
        "        embedding_matrix[index] = embedding\n",
        "    missing_embed_count = len(missing_embed_words)\n",
        "    print('# Words missing embedding : {}'.format(missing_embed_count))\n",
        "    print('Embedding shape : {}'.format(embedding_matrix.shape))\n",
        "    print(\"i: \", i_ )\n",
        "    return word2index, index2word, embedding_matrix\n",
        "\n",
        "def forward_transformation(dataframe, lowercase = True, filter_punc = True, filtering = \"a132\"):\n",
        "    grouped = dataframe.groupby('sentence').apply(lambda row : \n",
        "                        {'sent_id' : list(set(row['sent_id']))[0],\n",
        "                         'sentence' : list(set(row['sentence']))[0], \n",
        "                         'tags': [tag for tag in zip(row['target'], \n",
        "                            row['start'], row['end'], row['binary'], row['prob'])]})\n",
        "    sentences = []\n",
        "    for vals in grouped:\n",
        "        sent_id = vals['sent_id']\n",
        "        sentence = vals['sentence']\n",
        "        tags = vals['tags']\n",
        "        tags_without_labels = [(word, start, end) for word, start, end, binary, prob in tags]\n",
        "        all_tokens = all_tokens_with_index(sentence)\n",
        "        sent_repr = [(word, start, end, tags[tags_without_labels.index((word, start, end))][3],\n",
        "                     tags[tags_without_labels.index((word, start, end))][4])\n",
        "           if (word, start, end) in tags_without_labels \n",
        "          else (word, start, end, 0, 0.0) for word, index, start, end in all_tokens]\n",
        "        if lowercase:\n",
        "            sent_repr = [(word.lower(), start, end, binary, prob) \n",
        "                         for word, start, end, binary, prob in sent_repr]\n",
        "        if filter_punc:\n",
        "            sent_repr = list(filter(lambda vals : remove_punctuation(vals[0]), sent_repr))\n",
        "        if filtering:\n",
        "            sent_repr = list(filter(lambda vals : vals[0] != \"'s\", sent_repr))\n",
        "            sent_repr = list(filter(lambda vals : vals[0] != \"``\", sent_repr))\n",
        "        sentences.append({'sent_id' : sent_id, 'sentence' : sentence, 'seq' : sent_repr})\n",
        "    return sentences\n",
        "\n",
        "def split_sentence_seqs(sentences):\n",
        "    words, start_end, binary, prob = [], [], [] ,[]\n",
        "    for sent in sentences:\n",
        "        sequence = sent['seq']\n",
        "        curr_w, curr_se, curr_b, curr_p = map(list, zip(*[(vals[0], \n",
        "            (vals[1], vals[2]), vals[3], vals[4]) for vals in sequence]))\n",
        "        words.append(curr_w)\n",
        "        start_end.append(curr_se)\n",
        "        binary.append(curr_b)\n",
        "        prob.append(curr_p)\n",
        "    return words, start_end, binary, prob"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDje3oWHia4U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datasets.append(Dataset('train_all_test_wiki', \n",
        "        datasets[0].train.append(datasets[1].train).append(datasets[2].train), datasets[0].test))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZDkqP8kia4h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "dffb58d3-f2e5-45af-ac78-953b67d3149c"
      },
      "source": [
        "# Append train and test set\n",
        "dataset_sel = datasets[3]\n",
        "train_num_rows = dataset_sel.train.shape[0]\n",
        "train_num_sents = len(list(set(dataset_sel.train.sentence.values.tolist())))\n",
        "\n",
        "test_num_rows = dataset_sel.test.shape[0]\n",
        "test_num_sents = len(list(set(dataset_sel.test.sentence.values.tolist())))\n",
        "\n",
        "dataset = dataset_sel.train.append(dataset_sel.test)\n",
        "dataset['sent_id'] = dataset.groupby('sentence').ngroup()\n",
        "dataset_num_rows = dataset.shape[0]\n",
        "dataset_num_sents = len(list(set(dataset.sentence.values.tolist())))\n",
        "\n",
        "print('# Rows train : {}'.format(train_num_rows))\n",
        "print('# Rows test : {}'.format(test_num_rows))\n",
        "print('# Rows dataset : {}'.format(dataset_num_rows))\n",
        "\n",
        "print('# Sents train : {}'.format(train_num_sents))\n",
        "print('# Sents test : {}'.format(test_num_sents))\n",
        "print('# Sents dataset : {}'.format(dataset_num_sents))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Rows train : 27299\n",
            "# Rows test : 694\n",
            "# Rows dataset : 27993\n",
            "# Sents train : 1988\n",
            "# Sents test : 53\n",
            "# Sents dataset : 2041\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RobjIVe3649W",
        "colab_type": "text"
      },
      "source": [
        "Finally the Dataset to train the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYEiqcrybEO4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 929
        },
        "outputId": "0eef09a3-4da3-4f28-9ab0-6514125ab978"
      },
      "source": [
        "dataset"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>target</th>\n",
              "      <th>nat</th>\n",
              "      <th>non_nat</th>\n",
              "      <th>nat_marked</th>\n",
              "      <th>non_nat_marked</th>\n",
              "      <th>binary</th>\n",
              "      <th>prob</th>\n",
              "      <th>sent_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3XU9MCX6VODXPI3L8I02CM94TFB2R7</td>\n",
              "      <td>Normally , the land will be passed down to future generations in a way that recognizes the community 's traditional connection to that country .</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>Normally</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.05</td>\n",
              "      <td>1347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3XU9MCX6VODXPI3L8I02CM94TFB2R7</td>\n",
              "      <td>Normally , the land will be passed down to future generations in a way that recognizes the community 's traditional connection to that country .</td>\n",
              "      <td>28</td>\n",
              "      <td>34</td>\n",
              "      <td>passed</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.05</td>\n",
              "      <td>1347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3XU9MCX6VODXPI3L8I02CM94TFB2R7</td>\n",
              "      <td>Normally , the land will be passed down to future generations in a way that recognizes the community 's traditional connection to that country .</td>\n",
              "      <td>15</td>\n",
              "      <td>19</td>\n",
              "      <td>land</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3XU9MCX6VODXPI3L8I02CM94TFB2R7</td>\n",
              "      <td>Normally , the land will be passed down to future generations in a way that recognizes the community 's traditional connection to that country .</td>\n",
              "      <td>43</td>\n",
              "      <td>49</td>\n",
              "      <td>future</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.05</td>\n",
              "      <td>1347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3XU9MCX6VODXPI3L8I02CM94TFB2R7</td>\n",
              "      <td>Normally , the land will be passed down to future generations in a way that recognizes the community 's traditional connection to that country .</td>\n",
              "      <td>43</td>\n",
              "      <td>61</td>\n",
              "      <td>future generations</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.15</td>\n",
              "      <td>1347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>689</th>\n",
              "      <td>3W0KKJIARRAMOTSFYF06L10TKN9K8Z</td>\n",
              "      <td>Devotion ( Bhakti ) will cancel the effects of bad Karma and will bring a person closer to the true knowledge by purifying his mind .</td>\n",
              "      <td>100</td>\n",
              "      <td>109</td>\n",
              "      <td>knowledge</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.10</td>\n",
              "      <td>929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>690</th>\n",
              "      <td>3W0KKJIARRAMOTSFYF06L10TKN9K8Z</td>\n",
              "      <td>Devotion ( Bhakti ) will cancel the effects of bad Karma and will bring a person closer to the true knowledge by purifying his mind .</td>\n",
              "      <td>74</td>\n",
              "      <td>80</td>\n",
              "      <td>person</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>691</th>\n",
              "      <td>3W0KKJIARRAMOTSFYF06L10TKN9K8Z</td>\n",
              "      <td>Devotion ( Bhakti ) will cancel the effects of bad Karma and will bring a person closer to the true knowledge by purifying his mind .</td>\n",
              "      <td>95</td>\n",
              "      <td>99</td>\n",
              "      <td>true</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>692</th>\n",
              "      <td>3W0KKJIARRAMOTSFYF06L10TKN9K8Z</td>\n",
              "      <td>Devotion ( Bhakti ) will cancel the effects of bad Karma and will bring a person closer to the true knowledge by purifying his mind .</td>\n",
              "      <td>113</td>\n",
              "      <td>122</td>\n",
              "      <td>purifying</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0.75</td>\n",
              "      <td>929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>693</th>\n",
              "      <td>3W0KKJIARRAMOTSFYF06L10TKN9K8Z</td>\n",
              "      <td>Devotion ( Bhakti ) will cancel the effects of bad Karma and will bring a person closer to the true knowledge by purifying his mind .</td>\n",
              "      <td>127</td>\n",
              "      <td>131</td>\n",
              "      <td>mind</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.05</td>\n",
              "      <td>929</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>27993 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 id  \\\n",
              "0    3XU9MCX6VODXPI3L8I02CM94TFB2R7   \n",
              "1    3XU9MCX6VODXPI3L8I02CM94TFB2R7   \n",
              "2    3XU9MCX6VODXPI3L8I02CM94TFB2R7   \n",
              "3    3XU9MCX6VODXPI3L8I02CM94TFB2R7   \n",
              "4    3XU9MCX6VODXPI3L8I02CM94TFB2R7   \n",
              "..                              ...   \n",
              "689  3W0KKJIARRAMOTSFYF06L10TKN9K8Z   \n",
              "690  3W0KKJIARRAMOTSFYF06L10TKN9K8Z   \n",
              "691  3W0KKJIARRAMOTSFYF06L10TKN9K8Z   \n",
              "692  3W0KKJIARRAMOTSFYF06L10TKN9K8Z   \n",
              "693  3W0KKJIARRAMOTSFYF06L10TKN9K8Z   \n",
              "\n",
              "                                                                                                                                             sentence  \\\n",
              "0    Normally , the land will be passed down to future generations in a way that recognizes the community 's traditional connection to that country .   \n",
              "1    Normally , the land will be passed down to future generations in a way that recognizes the community 's traditional connection to that country .   \n",
              "2    Normally , the land will be passed down to future generations in a way that recognizes the community 's traditional connection to that country .   \n",
              "3    Normally , the land will be passed down to future generations in a way that recognizes the community 's traditional connection to that country .   \n",
              "4    Normally , the land will be passed down to future generations in a way that recognizes the community 's traditional connection to that country .   \n",
              "..                                                                                                                                                ...   \n",
              "689             Devotion ( Bhakti ) will cancel the effects of bad Karma and will bring a person closer to the true knowledge by purifying his mind .   \n",
              "690             Devotion ( Bhakti ) will cancel the effects of bad Karma and will bring a person closer to the true knowledge by purifying his mind .   \n",
              "691             Devotion ( Bhakti ) will cancel the effects of bad Karma and will bring a person closer to the true knowledge by purifying his mind .   \n",
              "692             Devotion ( Bhakti ) will cancel the effects of bad Karma and will bring a person closer to the true knowledge by purifying his mind .   \n",
              "693             Devotion ( Bhakti ) will cancel the effects of bad Karma and will bring a person closer to the true knowledge by purifying his mind .   \n",
              "\n",
              "     start  end              target  nat  non_nat  nat_marked  non_nat_marked  \\\n",
              "0        0    8            Normally   10       10           0               1   \n",
              "1       28   34              passed   10       10           0               1   \n",
              "2       15   19                land   10       10           0               0   \n",
              "3       43   49              future   10       10           1               0   \n",
              "4       43   61  future generations   10       10           1               2   \n",
              "..     ...  ...                 ...  ...      ...         ...             ...   \n",
              "689    100  109           knowledge   10       10           0               2   \n",
              "690     74   80              person   10       10           0               0   \n",
              "691     95   99                true   10       10           0               0   \n",
              "692    113  122           purifying   10       10           7               8   \n",
              "693    127  131                mind   10       10           0               1   \n",
              "\n",
              "     binary  prob  sent_id  \n",
              "0         1  0.05     1347  \n",
              "1         1  0.05     1347  \n",
              "2         0  0.00     1347  \n",
              "3         1  0.05     1347  \n",
              "4         1  0.15     1347  \n",
              "..      ...   ...      ...  \n",
              "689       1  0.10      929  \n",
              "690       0  0.00      929  \n",
              "691       0  0.00      929  \n",
              "692       1  0.75      929  \n",
              "693       1  0.05      929  \n",
              "\n",
              "[27993 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MplXgHaiia40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = forward_transformation(dataset)\n",
        "train_sentences = sentences[:train_num_sents]\n",
        "test_sentences = sentences[train_num_sents:]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u99Mj7Xcia5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words, start_end, binary, prob = split_sentence_seqs(sentences)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtMawZoJia5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_lens = [len(sent) for sent in words]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuhY0kB07BRo",
        "colab_type": "text"
      },
      "source": [
        "The dimensions of the embedding and vectors for the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw2BjkUGia6B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "52d9be7b-a73f-4034-8b86-eec337a03401"
      },
      "source": [
        "embedding_model = glove_models[0].model\n",
        "dimension = embedding_model.vector_size\n",
        "word2index, index2word, embedding = build_vocabulary(sentences, embedding_model, dimension)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Words : 96437\n",
            "# Vocab : 52458\n",
            "# embeding model  : 400000\n",
            "# Words missing embedding : 0\n",
            "Embedding shape : (52458, 300)\n",
            "i:  9838\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwQAks4z76Bk",
        "colab_type": "text"
      },
      "source": [
        "## Padding the input sequences and get the binaries labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTBmTLM_ia6b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1157d864-90a2-4f90-94d3-c33e6ec0b5f8"
      },
      "source": [
        "\n",
        "words_with_indices = [[word2index[word] for word in sent] for sent in words]\n",
        "sent_lens = [len(sentence['seq']) for sentence in sentences]\n",
        "sent_max_length = np.max(sent_lens)\n",
        "print('Max length sentence : {}'.format(sent_max_length))\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "words_padded = pad_sequences(maxlen=sent_max_length, sequences=words_with_indices, padding=\"post\", value=0)\n",
        "binary_padded = pad_sequences(maxlen=sent_max_length, sequences=binary, padding=\"post\", value=0)\n",
        "prob_padded = pad_sequences(maxlen=sent_max_length, sequences=prob, padding=\"post\", value=0, dtype=\"float\")\n",
        "\n",
        "binary_padded_categorical = [to_categorical(clazz, num_classes=2) for clazz in binary_padded]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max length sentence : 103\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BZhRBLd70kZ",
        "colab_type": "text"
      },
      "source": [
        "# Split the to train and test set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oN1hQu-Zia6m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2ff05f96-8e88-46fe-819b-fef655fa1e09"
      },
      "source": [
        "\n",
        "# (1) Training set\n",
        "train_words_padded = words_padded[:train_num_sents]\n",
        "train_binary_padded = binary_padded[:train_num_sents]\n",
        "train_binary_padded_categorical = binary_padded_categorical[:train_num_sents]\n",
        "train_prob_padded = prob_padded[:train_num_sents]\n",
        "train_start_end = start_end[:train_num_sents]\n",
        "\n",
        "# (2) Test set\n",
        "test_words_padded = words_padded[train_num_sents:]\n",
        "test_binary_padded = binary_padded[train_num_sents:]\n",
        "test_binary_padded_categorical = binary_padded_categorical[train_num_sents:]\n",
        "test_prob_padded = prob_padded[train_num_sents:]\n",
        "test_start_end = start_end[train_num_sents:]\n",
        "\n",
        "print('Training set length : {}'.format(len(train_words_padded)))\n",
        "print('Test set length : {}'.format(len(test_words_padded)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set length : 1988\n",
            "Test set length : 53\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4bac9cJ8VRl",
        "colab_type": "text"
      },
      "source": [
        "## Create a kera's callback to validate the model on train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkS5oYETia61",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import keras.callbacks\n",
        "from keras import backend as K\n",
        "class Metrics(keras.callbacks.Callback):\n",
        "    def __init__(self, validation_data):\n",
        "        self.f1_scores = []\n",
        "        self.validation_data = validation_data\n",
        "        \n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        predict = np.asarray(self.model.predict(self.validation_data[0]))\n",
        "        targ = self.validation_data[1]\n",
        "        targ = np.array(targ)\n",
        "        shape = targ.shape\n",
        "        targ = targ.reshape((shape[0]*shape[1], shape[2]))\n",
        "        targ = np.argmax(targ, axis = 1)\n",
        "        predict = predict.reshape((shape[0]*shape[1]), shape[2])\n",
        "        predict = np.argmax(predict, axis = 1)\n",
        "        self.f1s=f1_score(targ, predict)\n",
        "        print(\"\\nF1 Score:\")\n",
        "        print(f1_score(targ, np.ones(shape[0]*shape[1])))\n",
        "        self.f1_scores.append(self.f1s)\n",
        "        return"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dj66fbej8nZc",
        "colab_type": "text"
      },
      "source": [
        "## Create the keras model for the Complex Word Identification task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vNLhlSOia7P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "e3f641e3-7677-40fb-d111-4d4770a2d385"
      },
      "source": [
        "from keras.models import Model, Input\n",
        "from keras import backend as K\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
        "\n",
        "vocab_size = embedding.shape[0]\n",
        "dimension = embedding.shape[1]\n",
        "\n",
        "np.set_printoptions(threshold=np.inf)\n",
        "\n",
        "in_seq = Input(shape=(sent_max_length,))\n",
        "embed = Embedding(input_dim=vocab_size, output_dim=dimension, \\\n",
        "                  weights=[embedding], input_length=sent_max_length)(in_seq)\n",
        "drop = Dropout(0.1)(embed)\n",
        "lstm = Bidirectional(LSTM(units=150, return_sequences=True, recurrent_dropout=0.1))(drop)\n",
        "out = TimeDistributed(Dense(2, activation=\"softmax\"))(lstm) \n",
        "\n",
        "model = Model(in_seq, out)\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "metrics = Metrics((test_words_padded, np.array(test_binary_padded_categorical)))\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"functional_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 103)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_4 (Embedding)      (None, 103, 300)          15737400  \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 103, 300)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 103, 300)          541200    \n",
            "_________________________________________________________________\n",
            "time_distributed_4 (TimeDist (None, 103, 2)            602       \n",
            "=================================================================\n",
            "Total params: 16,279,202\n",
            "Trainable params: 16,279,202\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_otFVjW8y6q",
        "colab_type": "text"
      },
      "source": [
        "And Train it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrkzrTixia7e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "1f56889d-3a81-4b0f-acb6-381e3780e5b9"
      },
      "source": [
        "history = model.fit(train_words_padded, np.array(train_binary_padded_categorical), batch_size=10, \n",
        "                    epochs=3, validation_data = (test_words_padded, np.array(test_binary_padded_categorical)), \n",
        "                    verbose=1, callbacks=[metrics])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1187 - accuracy: 0.9582\n",
            "F1 Score:\n",
            "0.05660377358490566\n",
            "100/100 [==============================] - 76s 759ms/step - loss: 0.1187 - accuracy: 0.9582 - val_loss: 0.0514 - val_accuracy: 0.9755\n",
            "Epoch 2/3\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0467 - accuracy: 0.9799\n",
            "F1 Score:\n",
            "0.05660377358490566\n",
            "100/100 [==============================] - 77s 766ms/step - loss: 0.0467 - accuracy: 0.9799 - val_loss: 0.0491 - val_accuracy: 0.9800\n",
            "Epoch 3/3\n",
            " 31/100 [========>.....................] - ETA: 51s - loss: 0.0359 - accuracy: 0.9852"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEEbSlhi9DgR",
        "colab_type": "text"
      },
      "source": [
        "Now let´s plot some chart to see the model performance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7RJGF8rMQoe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "7315c90e-3b9d-4a16-edc9-4914d90fedf8"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnrEnuuA2lAe",
        "colab_type": "text"
      },
      "source": [
        "The F1 Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4x3xLps3ia7o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "a105d667-de04-4407-d7cb-20bf40d1dc10"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.set_style(\"darkgrid\")\n",
        "epoch_f1s = plt.plot(metrics.f1_scores)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPBh94CV9L6P",
        "colab_type": "text"
      },
      "source": [
        "## Optional, if you want to save the trained CWI model into your gdrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKf8dSMzuqwA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PuNmJecws4T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_save_name = 'model_CWI_full.h5'\n",
        "path_dir = F\"/content/gdrive/My Drive/{model_save_name}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTnoFxbiuv_I",
        "colab_type": "text"
      },
      "source": [
        "Save the model to google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJTyD4Qcwidq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model.save(path_dir)  # creates a HDF5 file 'model_CWI_full.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPnvDOhLunjF",
        "colab_type": "text"
      },
      "source": [
        "Retrieve the model from google drive (if decide to save it)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUGNP3AWzCnM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "3d778bbb-7ce5-4dc6-e85e-f3d9e3777b6a"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model_cwi = load_model(path_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXGGPCyr_My8",
        "colab_type": "text"
      },
      "source": [
        "## Now, let´s define some useful functions in order to use the CWI with some out of samples sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnlnwjm8_9pf",
        "colab_type": "text"
      },
      "source": [
        "Function for clean the data and remove non characters symbols"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3JMwj_HxKgl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words_ = set(stopwords.words('english'))\n",
        "def cleaner(word):\n",
        "  #Remove links\n",
        "  word = re.sub(r'((http|https)\\:\\/\\/)?[a-zA-Z0-9\\.\\/\\?\\:@\\-_=#]+\\.([a-zA-Z]){2,6}([a-zA-Z0-9\\.\\&\\/\\?\\:@\\-_=#])*', \n",
        "                '', word, flags=re.MULTILINE)\n",
        "  word = re.sub('[\\W]', ' ', word)\n",
        "  word = re.sub('[^a-zA-Z]', ' ', word)\n",
        "  return word.lower().strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Of08s9-AQ_R",
        "colab_type": "text"
      },
      "source": [
        "Function for to create the padded sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4QlGcVup70D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def process_input(input_text):\n",
        "  input_text = cleaner(input_text)\n",
        "  clean_text = []\n",
        "  index_list =[]\n",
        "  input_token = []\n",
        "  index_list_zipf = []\n",
        "  for i, word in enumerate(input_text.split()):\n",
        "    if word in word2index:\n",
        "      clean_text.append(word)\n",
        "      input_token.append(word2index[word])\n",
        "    else:\n",
        "      index_list.append(i)\n",
        "  input_padded = pad_sequences(maxlen=sent_max_length, sequences=[input_token], padding=\"post\", value=0)\n",
        "  return input_padded, index_list, len(clean_text)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B56mqE5V_n2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def complete_missing_word(pred_binary, index_list, len_list):\n",
        "  list_cwi_predictions = list(pred_binary[0][:len_list])\n",
        "  for i in index_list:\n",
        "    list_cwi_predictions.insert(i, 0)\n",
        "  return list_cwi_predictions\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QUAPHk7qVhT",
        "colab_type": "text"
      },
      "source": [
        "# Second part: The Candidates generation and selection using BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtOZMEJRR1kP",
        "colab_type": "text"
      },
      "source": [
        "First, install the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVYx5gVerXCF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "outputId": "2359662b-e0f7-4dcf-e1e0-48fe46f022e6"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install torch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\r\u001b[K     |▍                               | 10kB 21.7MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 3.4MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 4.6MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 4.9MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 4.0MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 4.4MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 4.9MB/s eta 0:00:01\r\u001b[K     |███▍                            | 81kB 5.3MB/s eta 0:00:01\r\u001b[K     |███▉                            | 92kB 5.7MB/s eta 0:00:01\r\u001b[K     |████▎                           | 102kB 5.5MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 133kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 153kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 163kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 174kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 184kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 194kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 204kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████                       | 215kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 225kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 235kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 245kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 256kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 266kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 276kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 286kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 296kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 307kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 317kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 327kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 337kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 348kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 358kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 368kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 378kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 389kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 399kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 409kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 419kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 430kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 440kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 450kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 460kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 471kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 481kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 491kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 501kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 512kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 522kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 532kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 542kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 552kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 563kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 573kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 583kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 593kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 604kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 614kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 624kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 634kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 645kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 655kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 665kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 675kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 686kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 696kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 706kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 716kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 727kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 737kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 747kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 757kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 768kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 778kB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\r\u001b[K     |▍                               | 10kB 28.6MB/s eta 0:00:01\r\u001b[K     |▊                               | 20kB 35.9MB/s eta 0:00:01\r\u001b[K     |█▏                              | 30kB 43.0MB/s eta 0:00:01\r\u001b[K     |█▌                              | 40kB 30.0MB/s eta 0:00:01\r\u001b[K     |█▉                              | 51kB 32.9MB/s eta 0:00:01\r\u001b[K     |██▎                             | 61kB 36.2MB/s eta 0:00:01\r\u001b[K     |██▋                             | 71kB 32.2MB/s eta 0:00:01\r\u001b[K     |███                             | 81kB 33.9MB/s eta 0:00:01\r\u001b[K     |███▍                            | 92kB 28.4MB/s eta 0:00:01\r\u001b[K     |███▊                            | 102kB 29.7MB/s eta 0:00:01\r\u001b[K     |████                            | 112kB 29.7MB/s eta 0:00:01\r\u001b[K     |████▌                           | 122kB 29.7MB/s eta 0:00:01\r\u001b[K     |████▉                           | 133kB 29.7MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 143kB 29.7MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 153kB 29.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 163kB 29.7MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 174kB 29.7MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 184kB 29.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 194kB 29.7MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 204kB 29.7MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 215kB 29.7MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 225kB 29.7MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 235kB 29.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 245kB 29.7MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 256kB 29.7MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 266kB 29.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 276kB 29.7MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 286kB 29.7MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 296kB 29.7MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 307kB 29.7MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 317kB 29.7MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 327kB 29.7MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 337kB 29.7MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 348kB 29.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 358kB 29.7MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 368kB 29.7MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 378kB 29.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 389kB 29.7MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 399kB 29.7MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 409kB 29.7MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 419kB 29.7MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 430kB 29.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 440kB 29.7MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 450kB 29.7MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 460kB 29.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 471kB 29.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 481kB 29.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 491kB 29.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 501kB 29.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 512kB 29.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 522kB 29.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 532kB 29.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 542kB 29.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 552kB 29.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 563kB 29.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 573kB 29.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 583kB 29.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 593kB 29.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 604kB 29.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 614kB 29.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 624kB 29.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 634kB 29.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 645kB 29.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 655kB 29.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 665kB 29.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 675kB 29.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 686kB 29.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 696kB 29.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 706kB 29.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 716kB 29.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 727kB 29.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 737kB 29.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 747kB 29.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 757kB 29.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 768kB 29.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 778kB 29.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 788kB 29.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 798kB 29.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 808kB 29.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 819kB 29.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 829kB 29.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 839kB 29.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 849kB 29.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 860kB 29.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 870kB 29.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 880kB 29.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 890kB 29.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 40.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 53.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=49e6a0ea3e506375adaebdae6fff2d48703db983413d46c9d619ef3e05d3f277\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.6.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mdl8mdOavews",
        "colab_type": "text"
      },
      "source": [
        "Load the BERT  model for masked languge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dtRGV68II0q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
        "\n",
        "bert_model = 'bert-large-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained(bert_model)\n",
        "model = BertForMaskedLM.from_pretrained(bert_model)\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCjuu21qNDk2",
        "colab_type": "text"
      },
      "source": [
        "To compute the **Zipf values**, we use the library **wordfreq**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIx9Fo5nLrlE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "0c290c29-e3a9-44fb-b356-e7a50cfbee47"
      },
      "source": [
        "!pip install wordfreq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wordfreq\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/24/a4c3d79335c2c35d84d1728614ff9115999f7218f30f73f29c81778accc7/wordfreq-2.3.2.tar.gz (32.8MB)\n",
            "\u001b[K     |████████████████████████████████| 32.8MB 91kB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.6/dist-packages (from wordfreq) (1.0.0)\n",
            "Collecting langcodes>=2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/1d/9b5ad179234206ad52f863c314851db7a00f69770c51d40c12c7513e628f/langcodes-2.0.0.tar.gz (4.9MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9MB 46.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from wordfreq) (2019.12.20)\n",
            "Collecting marisa-trie\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/95/d23071d0992dabcb61c948fb118a90683193befc88c23e745b050a29e7db/marisa-trie-0.7.5.tar.gz (270kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 50.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: wordfreq, langcodes, marisa-trie\n",
            "  Building wheel for wordfreq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wordfreq: filename=wordfreq-2.3.2-cp36-none-any.whl size=32817238 sha256=06ae5fc165fe0e06b9c2367a6fe77e7415f1ee0c9bc68c00f298899b6f87df8d\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/ba/84/ba6be76208bd2c2124b6586f7967fb87e9f9fb4b4827e5e2c9\n",
            "  Building wheel for langcodes (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langcodes: filename=langcodes-2.0.0-cp36-none-any.whl size=5044047 sha256=aae95a8b650e2960ac974723eda64370fa4764d5cc7b8f84fc8655245f284998\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/11/90/c7bba8118f3674d75e1457537635266a12538cf622a4684bb2\n",
            "  Building wheel for marisa-trie (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for marisa-trie: filename=marisa_trie-0.7.5-cp36-cp36m-linux_x86_64.whl size=862435 sha256=7d52331887bc23058fc5e0a977f1d1357b68a43ca81b7fa7fecc801dc15842c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/45/24/79/022624fc914f0e559fe8a1141aaff1f9df810905a13fc75d57\n",
            "Successfully built wordfreq langcodes marisa-trie\n",
            "Installing collected packages: marisa-trie, langcodes, wordfreq\n",
            "Successfully installed langcodes-2.0.0 marisa-trie-0.7.5 wordfreq-2.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9U5-S_GOT2u",
        "colab_type": "text"
      },
      "source": [
        "if we want the Zipf of the word \"stop\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piqCWoCgEvNr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "121d9c70-ac89-4f48-8267-f01388a1ae52"
      },
      "source": [
        "from wordfreq import zipf_frequency\n",
        "zipf_frequency('stop', 'en')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.49"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_XHvjDGOkej",
        "colab_type": "text"
      },
      "source": [
        "and for the word \"thwart\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q0W9MhJOhxz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5bcf518c-9037-4130-ee64-955767b5b21f"
      },
      "source": [
        "from wordfreq import zipf_frequency\n",
        "zipf_frequency('thwart', 'en')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.06"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clsADW6WRX4l",
        "colab_type": "text"
      },
      "source": [
        "As you can see the word \"stop\" is the most common."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqpV6nvyRlWc",
        "colab_type": "text"
      },
      "source": [
        "## Now the function to get the candidates out of BERT (MLM):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7l-H8loKIgMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def get_bert_candidates(input_text, list_cwi_predictions, numb_predictions_displayed = 10):\n",
        "  list_candidates_bert = []\n",
        "  for word,pred  in zip(input_text.split(), list_cwi_predictions):\n",
        "    if (pred and (pos_tag([word])[0][1] in ['NNS', 'NN', 'VBP', 'RB', 'VBG','VBD' ]))  or (zipf_frequency(word, 'en')) <3.1:\n",
        "      replace_word_mask = input_text.replace(word, '[MASK]')\n",
        "      text = f'[CLS]{replace_word_mask} [SEP] {input_text} [SEP] '\n",
        "      tokenized_text = tokenizer.tokenize(text)\n",
        "      masked_index = [i for i, x in enumerate(tokenized_text) if x == '[MASK]'][0]\n",
        "      indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "      segments_ids = [0]*len(tokenized_text)\n",
        "      tokens_tensor = torch.tensor([indexed_tokens])\n",
        "      segments_tensors = torch.tensor([segments_ids])\n",
        "      # Predict all tokens\n",
        "      with torch.no_grad():\n",
        "          outputs = model(tokens_tensor, token_type_ids=segments_tensors)\n",
        "          predictions = outputs[0][0][masked_index]\n",
        "      predicted_ids = torch.argsort(predictions, descending=True)[:numb_predictions_displayed]\n",
        "      predicted_tokens = tokenizer.convert_ids_to_tokens(list(predicted_ids))\n",
        "      list_candidates_bert.append((word, predicted_tokens))\n",
        "  return list_candidates_bert\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GEwJu8fP8g1",
        "colab_type": "text"
      },
      "source": [
        "# Simplifying new sentences:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-cd30Q6QJwb",
        "colab_type": "text"
      },
      "source": [
        "Given a list of new sentences with complex words:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4MRULkKNKNi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_texts = [ \n",
        " 'The Risk That Students Could Arrive at School With the Coronavirus As schools grapple with how to reopen, new estimates show that large parts of the country would probably see infected students if classrooms opened now.',\n",
        " 'How a photograph of a young man cradling his dying friend sent me on a journey across India.',\n",
        " 'Pro-democracy parties, which had hoped to ride widespread discontent to big gains, saw the yearlong delay as an attempt to thwart them.',\n",
        " 'Night after night, calm gave way to chaos. See what happened between the protesters and the federal agents.',\n",
        " 'Contact Tracing Is Failing in Many States. Here is Why. Inadequate testing and protracted delays in producing results have crippled tracking and hampered efforts to contain major outbreaks.',\n",
        " 'After an initial decrease in the youth detention population, the rate of release has slowed, and the gap between white youth and Black youth has grown.'\n",
        " 'A laboratory experiment hints at some of the ways the virus might elude antibody treatments. Combining therapies could help, experts said.',\n",
        " 'Though I may not be here with you, I urge you to answer the highest calling of your heart and stand up for what you truly believe.',\n",
        " 'The research does not prove that infected children are contagious, but it should influence the debate about reopening schools, some experts said.',\n",
        " 'Dropping antibody counts are not a sign that our immune system is failing against the coronavirus, nor an omen that we can not develop a viable vaccine.',\n",
        " 'The Senate majority leader has said he will not approve a stimulus package without a “liability shield,” but top White House officials say they do not see it as essential.',\n",
        " 'Campaign efforts to refocus come as the president continues to push divisive messages that have frustrated his own party.'\n",
        "] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Q6jPaqVQSHj",
        "colab_type": "text"
      },
      "source": [
        "We apply the simplifier to see how it is performing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFl_PPkLOGyG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "outputId": "c425dbfe-4683-4905-f187-cea4702b2f72"
      },
      "source": [
        "for input_text in list_texts:\n",
        "  new_text = input_text\n",
        "  input_padded, index_list, len_list = process_input(input_text)\n",
        "  pred_cwi = model_cwi.predict(input_padded)\n",
        "  pred_cwi_binary = np.argmax(pred_cwi, axis = 2)\n",
        "  complete_cwi_predictions = complete_missing_word(pred_cwi_binary, index_list, len_list)\n",
        "  bert_candidates =   get_bert_candidates(input_text, complete_cwi_predictions)\n",
        "  for word_to_replace, l_candidates in bert_candidates:\n",
        "    tuples_word_zipf = []\n",
        "    for w in l_candidates:\n",
        "      if w.isalpha():\n",
        "        tuples_word_zipf.append((w, zipf_frequency(w, 'en')))\n",
        "    tuples_word_zipf = sorted(tuples_word_zipf, key = lambda x: x[1], reverse=True)\n",
        "    new_text = re.sub(word_to_replace, tuples_word_zipf[0][0], new_text) \n",
        "  print(\"Original text: \", input_text )\n",
        "  print(\"Simplified text:\", new_text, \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original text:  The Risk That Students Could Arrive at School With the Coronavirus As schools grapple with how to reopen, new estimates show that large parts of the country would probably see infected students if classrooms opened now.\n",
            "Simplified text: The Risk That Students Could Arrive at School With the disease As schools deal with how to open new numbers show that large parts of the country would maybe see infected students if they opened now. \n",
            "\n",
            "Original text:  How a photograph of a young man cradling his dying friend sent me on a journey across India.\n",
            "Simplified text: How a shot of a young man and his dead friend sent me on a tour across India. \n",
            "\n",
            "Original text:  Pro-democracy parties, which had hoped to ride widespread discontent to big gains, saw the yearlong delay as an attempt to thwart them.\n",
            "Simplified text: Pro-democracy parties, which had hoped to ride widespread opposition to big gains, saw the year delay as an attempt to stop while \n",
            "\n",
            "Original text:  Night after night, calm gave way to chaos. See what happened between the protesters and the federal agents.\n",
            "Simplified text: Night after night, order gave way to confusion See what happened between the people and the federal agents. \n",
            "\n",
            "Original text:  Contact Tracing Is Failing in Many States. Here is Why. Inadequate testing and protracted delays in producing results have crippled tracking and hampered efforts to contain major outbreaks.\n",
            "Simplified text: Contact testing Is failed in Many States. Here is Why. poor testing and protracted delay in producing results have crippled track and hampered efforts to contain major cases \n",
            "\n",
            "Original text:  After an initial decrease in the youth detention population, the rate of release has slowed, and the gap between white youth and Black youth has grown.A laboratory experiment hints at some of the ways the virus might elude antibody treatments. Combining therapies could help, experts said.\n",
            "Simplified text: After an initial fall in the youth prison population, the rate of release has increased and the gap between white youth and Black youth has the laboratory research looks at some of the ways the virus might reach antibody and using them could help, experts said. \n",
            "\n",
            "Original text:  Though I may not be here with you, I urge you to answer the highest calling of your heart and stand up for what you truly believe.\n",
            "Simplified text: Though I may not be here with you, I ask you to answer the highest calling of your heart and stand up for what you truly believe. \n",
            "\n",
            "Original text:  The research does not prove that infected children are contagious, but it should influence the debate about reopening schools, some experts said.\n",
            "Simplified text: The work does not show that infected children are sick but it should change the question about open schools, some experts said. \n",
            "\n",
            "Original text:  Dropping antibody counts are not a sign that our immune system is failing against the coronavirus, nor an omen that we can not develop a viable vaccine.\n",
            "Simplified text: Dropping blood counts are not a sign that our immune system is failed against the disease nor an order that we can not develop a viable response \n",
            "\n",
            "Original text:  The Senate majority leader has said he will not approve a stimulus package without a “liability shield,” but top White House officials say they do not see it as essential.\n",
            "Simplified text: The Senate majority leader has said he will not approve a tax package without a risk defense but top White House officials say they do not see it as possible \n",
            "\n",
            "Original text:  Campaign efforts to refocus come as the president continues to push divisive messages that have frustrated his own party.\n",
            "Simplified text: the efforts to lead come as the president continues to push the messages that have frustrated his own party. \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uX_rtWzTQnEZ",
        "colab_type": "text"
      },
      "source": [
        "**Pretty** **good results**"
      ]
    }
  ]
}